# LLM Ethics & Safety Glossary ðŸ“š

## A

### Alignment
The process of ensuring AI systems behave in accordance with human values and intentions.

### Artificial General Intelligence (AGI)
AI systems that possess human-like general problem-solving abilities across various domains.

## B

### Bias
Systematic prejudice in AI model outputs, often reflecting societal biases in training data.

## C

### Capability Control
Methods to limit or control an AI system's capabilities for safety purposes.

## D

### Distributional Shift
Changes in the statistical properties between training and deployment environments.

## E

### Ethical AI
AI systems designed and deployed with consideration for moral principles and societal impact.

## F

### Fine-tuning
The process of adapting a pre-trained model to specific tasks while maintaining safety constraints.

## H

### Hallucination
When an LLM generates false or misleading information that appears plausible but is incorrect.

## P

### Prompt Injection
Security vulnerability where malicious inputs manipulate an LLM's behavior.

## R

### Robustness
An AI system's ability to maintain safe and reliable performance across various conditions.

## S

### Scalable Oversight
Methods for maintaining control and supervision as AI systems become more capable.

## T

### Transparency
The degree to which an AI system's decision-making process can be understood and analyzed.

## V

### Value Learning
Techniques for teaching AI systems to understand and adhere to human values. 